{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaaRavi/Butterfly-cnn/blob/preprocessing/Butteryfly_cnn_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the data"
      ],
      "metadata": {
        "id": "qN-ypjJZY2ES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## downloading"
      ],
      "metadata": {
        "id": "XeAQLmiTqNiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/butterfly-data"
      ],
      "metadata": {
        "id": "mtb01kDUYz7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b86489e-aca4-4c5d-f56e-6392e27cc5fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/butterfly-data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the kaggle api token\n",
        "!mkdir ~/.kaggle\n",
        "file_id = \"1zSRznA3TypBwqP75WcOuv6X3tbaYDiNJ\"\n",
        "file_download_link = \"https://docs.google.com/uc?export=download&id=\" + file_id\n",
        "!wget -O ~/.kaggle/kaggle.json --no-check-certificate \"$file_download_link\"\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list > datasets.txt\n",
        "!head 5 datasets.txt\n",
        "!pip install tensorflow_io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ZcKne_gG9v",
        "outputId": "6ed6f59f-6e9b-47f5-f4da-28d11312dfe8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "--2022-11-24 03:07:54--  https://docs.google.com/uc?export=download&id=1zSRznA3TypBwqP75WcOuv6X3tbaYDiNJ\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.24.113, 74.125.24.101, 74.125.24.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.24.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-bk-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/oht66ffrqt1fhcn8b298ba47ja5me99m/1669259250000/09300047399178709700/*/1zSRznA3TypBwqP75WcOuv6X3tbaYDiNJ?e=download&uuid=aa9132e1-6139-41d8-bf0d-d0b8b3e3313b [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-24 03:07:54--  https://doc-10-bk-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/oht66ffrqt1fhcn8b298ba47ja5me99m/1669259250000/09300047399178709700/*/1zSRznA3TypBwqP75WcOuv6X3tbaYDiNJ?e=download&uuid=aa9132e1-6139-41d8-bf0d-d0b8b3e3313b\n",
            "Resolving doc-10-bk-docs.googleusercontent.com (doc-10-bk-docs.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n",
            "Connecting to doc-10-bk-docs.googleusercontent.com (doc-10-bk-docs.googleusercontent.com)|74.125.24.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66 [application/json]\n",
            "Saving to: ‘/root/.kaggle/kaggle.json’\n",
            "\n",
            "/root/.kaggle/kaggl 100%[===================>]      66  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-24 03:07:55 (1.50 MB/s) - ‘/root/.kaggle/kaggle.json’ saved [66/66]\n",
            "\n",
            "head: cannot open '5' for reading: No such file or directory\n",
            "==> datasets.txt <==\n",
            "ref                                                         title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "akshaydattatraykhare/diabetes-dataset                       Diabetes Dataset                                      9KB  2022-10-06 08:55:25          17290        502  1.0              \n",
            "akshaydattatraykhare/data-for-admission-in-the-university   Data for Admission in the University                  4KB  2022-10-27 11:05:45           4670        111  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                   Salary Prediction                                     3MB  2022-11-16 13:52:31           1149         35  1.0              \n",
            "meirnizri/covid19-dataset                                   COVID-19 Dataset                                      5MB  2022-11-13 15:47:17           1707         52  1.0              \n",
            "piterfm/fifa-football-world-cup                             FIFA Football World Cup                              69KB  2022-11-23 12:09:24            788         35  1.0              \n",
            "dheerajmukati/india-gdp-19602022                            India GDP 1960-2022                                   1KB  2022-11-11 12:08:46            802         29  1.0              \n",
            "whenamancodes/predict-diabities                             Predict Diabetes                                      9KB  2022-11-09 12:18:49           2294         51  1.0              \n",
            "zvr842/global-pollution-by-counties                         Global pollution by counties                         15KB  2022-11-14 10:57:31            867         26  0.9705882        \n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (0.28.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.28.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_io) (0.28.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d gpiosenka/butterfly-images40-species -p /content/butterfly-data/ --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1KHuM9ib37n",
        "outputId": "56edc07a-4261-432f-a859-fddc972051cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading butterfly-images40-species.zip to /content/butterfly-data\n",
            " 99% 451M/454M [00:21<00:00, 22.9MB/s]\n",
            "100% 454M/454M [00:21<00:00, 22.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "uC9v8yap0_uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100  \n",
        "BATCH_SIZE = 128\n",
        "CHANNELS = 3\n",
        "IMAGE_SIZE = 224"
      ],
      "metadata": {
        "id": "AUO_mxTF1Bm4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading the data"
      ],
      "metadata": {
        "id": "zVUD1knMqTCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "from tensorflow.keras import models, layers, preprocessing, Sequential\n",
        "import tensorflow.keras\n",
        "\n",
        "print(\"Training Data:\\n---------------\")\n",
        "training_data = preprocessing.image_dataset_from_directory(\n",
        "    \"/content/butterfly-data/train\", \n",
        "    batch_size=BATCH_SIZE, \n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(\"\\n\\nTesting Data:\\n---------------\")\n",
        "testing_data = preprocessing.image_dataset_from_directory(\n",
        "    \"/content/butterfly-data/test\", \n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    shuffle=True\n",
        ")\n",
        "print(\"\\n\\nValidation Data:\\n---------------\")\n",
        "validation_data = preprocessing.image_dataset_from_directory(\n",
        "    \"/content/butterfly-data/valid\", \n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0nnVL-xo4Tm",
        "outputId": "84b128d3-a4c0-4011-9013-4b15ec0bf5fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "---------------\n",
            "Found 12639 files belonging to 100 classes.\n",
            "\n",
            "\n",
            "Testing Data:\n",
            "---------------\n",
            "Found 500 files belonging to 100 classes.\n",
            "\n",
            "\n",
            "Validation Data:\n",
            "---------------\n",
            "Found 500 files belonging to 100 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if the data \n",
        "classes = training_data.class_names\n",
        "print(\n",
        "    \"Num classes: \", len(classes),\n",
        "    \"\\nClass Names: \", classes\n",
        ")"
      ],
      "metadata": {
        "id": "hWUZy5Jx7BT2",
        "outputId": "97ab0229-a54e-4dc0-968c-f2cefbeaee4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num classes:  100 \n",
            "Class Names:  ['ADONIS', 'AFRICAN GIANT SWALLOWTAIL', 'AMERICAN SNOOT', 'AN 88', 'APPOLLO', 'ARCIGERA FLOWER MOTH', 'ATALA', 'ATLAS MOTH', 'BANDED ORANGE HELICONIAN', 'BANDED PEACOCK', 'BANDED TIGER MOTH', 'BECKERS WHITE', 'BIRD CHERRY ERMINE MOTH', 'BLACK HAIRSTREAK', 'BLUE MORPHO', 'BLUE SPOTTED CROW', 'BROOKES BIRDWING', 'BROWN ARGUS', 'BROWN SIPROETA', 'CABBAGE WHITE', 'CAIRNS BIRDWING', 'CHALK HILL BLUE', 'CHECQUERED SKIPPER', 'CHESTNUT', 'CINNABAR MOTH', 'CLEARWING MOTH', 'CLEOPATRA', 'CLODIUS PARNASSIAN', 'CLOUDED SULPHUR', 'COMET MOTH', 'COMMON BANDED AWL', 'COMMON WOOD-NYMPH', 'COPPER TAIL', 'CRECENT', 'CRIMSON PATCH', 'DANAID EGGFLY', 'EASTERN COMA', 'EASTERN DAPPLE WHITE', 'EASTERN PINE ELFIN', 'ELBOWED PIERROT', 'EMPEROR GUM MOTH', 'GARDEN TIGER MOTH', 'GIANT LEOPARD MOTH', 'GLITTERING SAPPHIRE', 'GOLD BANDED', 'GREAT EGGFLY', 'GREAT JAY', 'GREEN CELLED CATTLEHEART', 'GREEN HAIRSTREAK', 'GREY HAIRSTREAK', 'HERCULES MOTH', 'HUMMING BIRD HAWK MOTH', 'INDRA SWALLOW', 'IO MOTH', 'Iphiclus sister', 'JULIA', 'LARGE MARBLE', 'LUNA MOTH', 'MADAGASCAN SUNSET MOTH', 'MALACHITE', 'MANGROVE SKIPPER', 'MESTRA', 'METALMARK', 'MILBERTS TORTOISESHELL', 'MONARCH', 'MOURNING CLOAK', 'OLEANDER HAWK MOTH', 'ORANGE OAKLEAF', 'ORANGE TIP', 'ORCHARD SWALLOW', 'PAINTED LADY', 'PAPER KITE', 'PEACOCK', 'PINE WHITE', 'PIPEVINE SWALLOW', 'POLYPHEMUS MOTH', 'POPINJAY', 'PURPLE HAIRSTREAK', 'PURPLISH COPPER', 'QUESTION MARK', 'RED ADMIRAL', 'RED CRACKER', 'RED POSTMAN', 'RED SPOTTED PURPLE', 'ROSY MAPLE MOTH', 'SCARCE SWALLOW', 'SILVER SPOT SKIPPER', 'SIXSPOT BURNET MOTH', 'SLEEPY ORANGE', 'SOOTYWING', 'SOUTHERN DOGFACE', 'STRAITED QUEEN', 'TROPICAL LEAFWING', 'TWO BARRED FLASHER', 'ULYSES', 'VICEROY', 'WHITE LINED SPHINX MOTH', 'WOOD SATYR', 'YELLOW SWALLOW TAIL', 'ZEBRA LONG WING']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "5qRDblKV1UWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert all values to grayscale since butterflies tend to be more colorful, having a high RGB value as compared to moths. The neural network will favor higher values of RGB/brighter images compared to the lower values of RGB/darker images. This can be seen in butterflies which tend to be brighter than moths, so the network would prefer butterfly images over moth images. \n",
        "High RGB → higher grayscale value. Similarly the other way around.\n",
        "To avoid skewing the ML model, we convert them to grayscale, and to make our model run efficiently and effectively we add them up and average them out. \n"
      ],
      "metadata": {
        "id": "KwDiCQnehIcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.image import rgb_to_grayscale\n",
        "import cv2\n",
        "mean_array = []\n",
        "#laplacian_array = []\n",
        "for images, labels in training_data.as_numpy_iterator():\n",
        "    for image in images:\n",
        "        mean_array.append(np.asarray(rgb_to_grayscale(image)).reshape(-1, 1).mean())\n",
        "        #laplacian_array.append(np.asarray(np.random.laplace(image)).reshape(-1, 1).var())"
      ],
      "metadata": {
        "id": "qtI1vBvx6NHP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the grayscale averages will then be added to an array for further use. Let’s call that the mean_array. Using the mean_array, we will compute useful values such as the mean, median, standard deviation, min, and max values. These values help us better understand the distribution of the data."
      ],
      "metadata": {
        "id": "5-1qH--qgn8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(mean_array)"
      ],
      "metadata": {
        "id": "XiKVsOkjBaw3",
        "outputId": "32ed1247-7370-49f0-a34c-dab43e3b1751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12639"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(laplacian_array)"
      ],
      "metadata": {
        "id": "tFugNeeroi7y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_array[:5]"
      ],
      "metadata": {
        "id": "oTKVlbVTB7qr",
        "outputId": "8e21b1ad-ea44-4100-e8ce-f0329df1badd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[129.17303, 125.4766, 120.61618, 119.29955, 86.969055]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#laplacian_array[:5]"
      ],
      "metadata": {
        "id": "Ss9WEG7Ooo07"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_array = np.asarray(mean_array)\n",
        "median = np.median(mean_array)\n",
        "std_dev = np.std(mean_array)\n",
        "min = mean_array.min()\n",
        "max = mean_array.max()\n",
        "mean = np.mean(mean_array)\n",
        "\n",
        "# laplacian_array = np.asarray(laplacian_array)\n",
        "# lap_median = np.median(laplacian_array)\n",
        "# lap_std_dev = np.std(laplacian_array)\n",
        "# lap_min = laplacian_array.min()\n",
        "# lap_max = laplacian_array.max()\n",
        "# lap_mean = np.mean(laplacian_array)"
      ],
      "metadata": {
        "id": "nIo_VlNnCAYl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    \"\\nImage Grayscale Values:\",\n",
        "    \"\\n----------\", \n",
        "    \"\\n\\tMean: \", mean,\n",
        "    \"\\n\\tMedian: \", median,\n",
        "    \"\\n\\tStandard Deviation: \", std_dev,\n",
        "    \"\\n\\tMinimum: \", min,\n",
        "    \"\\n\\tMaximum: \", max\n",
        ")\n",
        "# print(\n",
        "#     \"\\nImage Laplacian Values:\",\n",
        "#     \"\\n----------\", \n",
        "#     \"\\n\\tMean: \", lap_mean,\n",
        "#     \"\\n\\tMedian: \", lap_median,\n",
        "#     \"\\n\\tStandard Deviation: \", lap_std_dev,\n",
        "#     \"\\n\\tMinimum: \", lap_min,\n",
        "#     \"\\n\\tMaximum: \", lap_max\n",
        "# )"
      ],
      "metadata": {
        "id": "PiBiGk1kCvxp",
        "outputId": "0b38065f-2a2b-45cc-ec6d-f90ca478a917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image Grayscale Values: \n",
            "---------- \n",
            "\tMean:  116.32708 \n",
            "\tMedian:  114.14225 \n",
            "\tStandard Deviation:  29.468502 \n",
            "\tMinimum:  13.593116 \n",
            "\tMaximum:  242.44257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The min and max values show that our dataset is evenly distributed. We can also see that our mean is close to the center-most value which shows us that there are minimal outliers."
      ],
      "metadata": {
        "id": "ulvtyNJFj84X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the images"
      ],
      "metadata": {
        "id": "8HVjyTdP686z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot a random image of each class of butterflies and moths from the training dataset. This stands as a visual representation of the data we have so that it makes visualization easier."
      ],
      "metadata": {
        "id": "Sh-vvJZkhVDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VhUeQR9TFY_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(30,30))\n",
        "# for images, labels in training_data.take(1):\n",
        "#     #print(labels)\n",
        "#     for j in range(100):\n",
        "#         axis = plt.subplot(10, 10, j + 1)\n",
        "#         plt.imshow(np.asarray(images[j]).astype(\"uint8\"))\n",
        "#         plt.title(classes[labels[j]])\n",
        "#         plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "vNpd5Gbt4unq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "bRzkRs0sHoB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_preprocessing = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "    layers.GaussianNoise(2.0),\n",
        "    #tfio.experimental.filter.laplacian()\n",
        "\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomCrop(IMAGE_SIZE, IMAGE_SIZE)\n",
        "])"
      ],
      "metadata": {
        "id": "FENvgs2hHr5t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = training_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "testing_data = testing_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "validation_data = validation_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "wCKXgNFSlCyH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (128, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "model = models.Sequential([\n",
        "    data_preprocessing,\n",
        "    layers.Conv2D(128, (3,3), activation = 'relu', input_shape = INPUT_SHAPE),\n",
        "    layers.MaxPooling2D((4,4)),\n",
        "    layers.Conv2D(32, (3,3), activation = 'relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units = 128, activation = 'relu'),\n",
        "    #layers.Dense(units = 500, activation = 'relu'),\n",
        "    layers.Dense(units = 100, activation = 'sigmoid')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "bQPyhIhkSDRM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape = INPUT_SHAPE)\n",
        "\n"
      ],
      "metadata": {
        "id": "cDmVC1RZiE8B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), \n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "              metrics = ['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "EumIabMJlec8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_data, batch_size = BATCH_SIZE, validation_data = validation_data, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bityvc1WfQUZ",
        "outputId": "fc65e89e-1998-427c-d29d-ca8d8d1dcdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "99/99 [==============================] - 45s 458ms/step - loss: 4.6047 - accuracy: 0.0137 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
            "Epoch 2/100\n",
            "99/99 [==============================] - 44s 446ms/step - loss: 4.6040 - accuracy: 0.0148 - val_loss: 4.6053 - val_accuracy: 0.0100\n",
            "Epoch 3/100\n",
            "85/99 [========================>.....] - ETA: 6s - loss: 4.6034 - accuracy: 0.0151"
          ]
        }
      ]
    }
  ]
}